{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8303,
     "status": "ok",
     "timestamp": 1751266239206,
     "user": {
      "displayName": "nandini giri",
      "userId": "07159343548715606743"
     },
     "user_tz": -330
    },
    "id": "0EmrVDKzmP9X",
    "outputId": "fb47ca40-f24c-4749-f1ab-db377562dc50"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.11/dist-packages (0.8.5)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (0.6.15)\n",
      "Requirement already satisfied: google-api-core in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.25.1)\n",
      "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.173.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.38.0)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (5.29.5)\n",
      "Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.11.7)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.14.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (1.70.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (2.32.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
      "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (0.4.1)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.73.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.3)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2025.6.15)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pip install google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1751266255349,
     "user": {
      "displayName": "nandini giri",
      "userId": "07159343548715606743"
     },
     "user_tz": -330
    },
    "id": "z23EncNembMf"
   },
   "outputs": [],
   "source": [
    "\n",
    "import google.generativeai as genai\n",
    "\n",
    "#  Set your API key\n",
    "genai.configure(api_key=\"Your Api key\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1751266282164,
     "user": {
      "displayName": "nandini giri",
      "userId": "07159343548715606743"
     },
     "user_tz": -330
    },
    "id": "si5w1-xFmjAl"
   },
   "outputs": [],
   "source": [
    "# Load the Gemini model (text-only model)\n",
    "model = genai.GenerativeModel('gemini-1.5-flash')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pUMCLm4Dm-Ax"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 367
    },
    "executionInfo": {
     "elapsed": 3077,
     "status": "ok",
     "timestamp": 1751266366848,
     "user": {
      "displayName": "nandini giri",
      "userId": "07159343548715606743"
     },
     "user_tz": -330
    },
    "id": "dTFfv8ANmsfM",
    "outputId": "95e9a8e3-47f8-4bf9-a3f5-4deb413d1fd6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Zero-shot Output:\n",
      " The most common and natural translation of \"Good morning, how are you?\" in Marathi is:\n",
      "\n",
      "**सकाळी शुभेच्छा, कसे आहात? (Sakāḷī śubhecchā, kase āhāt?)**\n",
      "\n",
      "This directly translates to \"Good morning wishes, how are you?\".  The use of \"शुभेच्छा\" (śubhecchā) - wishes - makes it a more polite and formal way to say it.\n",
      "\n",
      "A slightly less formal, but still perfectly acceptable option is:\n",
      "\n",
      "**सकाळी शुभेच्छा, तुम्ही कसे आहात? (Sakāḷī śubhecchā, tumhī kase āhāt?)**\n",
      "\n",
      "This uses \"तुम्ही\" (tumhī) which is the polite \"you\" form.\n",
      "\n",
      "If you are speaking to a friend or someone you are very familiar with, you could use:\n",
      "\n",
      "**सकाळी छान, कसे आहेस? (Sakāḷī chān, kase āhes?)**\n",
      "\n",
      "This uses \"आहेस\" (āhes), the informal \"are you?\" and \"छान\" (chān), meaning \"nice\" or \"good\", to make it more casual.  (Note the change to singular 'आहेस' since you're addressing someone informally).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Zero-shot: Ask a question without any examples\n",
    "prompt_zero = \"Translate this sentence into Marathi : 'Good morning, how are you?'\"\n",
    "\n",
    "response_zero = model.generate_content(prompt_zero)\n",
    "print(\" Zero-shot Output:\\n\", response_zero.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "executionInfo": {
     "elapsed": 2942,
     "status": "ok",
     "timestamp": 1751266438097,
     "user": {
      "displayName": "nandini giri",
      "userId": "07159343548715606743"
     },
     "user_tz": -330
    },
    "id": "3BzflJFbm3Uc",
    "outputId": "3ef78038-3517-4b64-a4d3-07b44c23e4e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Few-shot Output:\n",
      " Let's translate these sentences, keeping in mind that the original English sentences are being used as a guide, not a direct translation source.  The French is irrelevant for the Marathi translation.\n",
      "\n",
      "1. **Hello, how are you?**  →  नमस्कार, कसे आहात? (Namaskar, kase aahat?) - This is a formal greeting. For informal, you could use \"नमस्कार, काय चाललय?\" (Namaskar, kay challay?) which translates more to \"Hello, what's up?\".\n",
      "\n",
      "2. **What is your name?** → तुमचे नाव काय आहे? (Tumche nav kay aahe?) - This is a polite and formal way to ask.  An informal way would be \"तुझं नाव काय आहे?\" (Tujhe nav kay aahe?).\n",
      "\n",
      "3. **I love programming.** → मला प्रोग्रामिंग आवडते. (Mala programming aavadte.)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Few-shot: Give a few examples in the prompt\n",
    "prompt_few = \"\"\"\n",
    "Translate these sentences to marathi:\n",
    "1. Hello, how are you? → Bonjour, comment ça va ?\n",
    "2. What is your name? → Comment tu t'appelles ?\n",
    "3. I love programming. →\n",
    "\"\"\"\n",
    "\n",
    "response_few = model.generate_content(prompt_few)\n",
    "print(\"\\n Few-shot Output:\\n\", response_few.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 106
    },
    "executionInfo": {
     "elapsed": 2750,
     "status": "ok",
     "timestamp": 1751266492655,
     "user": {
      "displayName": "nandini giri",
      "userId": "07159343548715606743"
     },
     "user_tz": -330
    },
    "id": "dUkKv0nCnR6v",
    "outputId": "0ffbdf8b-8288-408b-fefa-ab86eab46071"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Instruction-style Output:\n",
      " The Great Wall of China, a structure over 13,000 miles long, was built to defend Chinese states against invaders.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Instruction-style: Direct command\n",
    "prompt_instruction = \"Summarize the following: 'The Great Wall of China was built to protect Chinese states from invasions. It spans over 13,000 miles.'\"\n",
    "\n",
    "response_instruction = model.generate_content(prompt_instruction)\n",
    "print(\"\\n Instruction-style Output:\\n\", response_instruction.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "executionInfo": {
     "elapsed": 1902,
     "status": "ok",
     "timestamp": 1751266549998,
     "user": {
      "displayName": "nandini giri",
      "userId": "07159343548715606743"
     },
     "user_tz": -330
    },
    "id": "rAvQNNlHnfPc",
    "outputId": "d86436cc-c8cd-4e21-c43d-d0621a02f65b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Chain-of-Thought Output:\n",
      " The train's speed is 60 km/h, and it travels for 3 hours.  To find the distance, we multiply the speed by the time:\n",
      "\n",
      "Distance = Speed × Time\n",
      "Distance = 60 km/h × 3 h\n",
      "Distance = 180 km\n",
      "\n",
      "The train will go 180 km in 3 hours.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Chain-of-Thought: Ask to reason step-by-step\n",
    "prompt_cot = \"Q: A train travels at 60 km/h. How far will it go in 3 hours?\\nA: Let's think step-by-step.\"\n",
    "\n",
    "response_cot = model.generate_content(prompt_cot)\n",
    "print(\"\\nChain-of-Thought Output:\\n\", response_cot.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "executionInfo": {
     "elapsed": 4775,
     "status": "ok",
     "timestamp": 1751266573368,
     "user": {
      "displayName": "nandini giri",
      "userId": "07159343548715606743"
     },
     "user_tz": -330
    },
    "id": "YrZrIh2CntfC",
    "outputId": "c18d39bd-0eda-4932-ddc6-6ccf0b3a308c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Role-based Output:\n",
      " Imagine you're learning to bake a cake.  You have a recipe (your model) and you try different ingredients and baking times (your data).\n",
      "\n",
      "**Overfitting** is like memorizing the exact outcome of every single cake you've *ever* baked, instead of learning the general principles of baking.\n",
      "\n",
      "You might get perfect results for those *specific* cakes – you can even predict their exact texture and taste perfectly.  But if you try a slightly different recipe (new data), your \"memorized\" recipe will fail miserably.  You'll make a terrible cake because you didn't learn the underlying rules, just the specifics of the cakes you already baked.\n",
      "\n",
      "In data science terms:\n",
      "\n",
      "Overfitting happens when your model learns the training data *too well*, including the noise and random fluctuations. It becomes so specialized to the training data that it performs poorly on new, unseen data (the \"test\" data).  It's essentially memorizing the training data instead of learning the underlying patterns.  The model is too complex for the amount of data available.\n",
      "\n",
      "The solution often involves:\n",
      "\n",
      "* **Simplifying the model:** Use a less complex model with fewer parameters.\n",
      "* **Getting more data:** More data helps the model generalize better.\n",
      "* **Regularization:**  Adding penalties to the model to discourage it from becoming too complex.\n",
      "* **Cross-validation:**  Testing the model on different subsets of the data to get a better estimate of its performance on unseen data.\n",
      "\n",
      "\n",
      "Essentially, you want a model that generalizes well, not one that just performs well on the data it's already seen.  You want a baker who understands the principles of baking, not just someone who can perfectly replicate a few specific cakes.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Role-based: Ask model to take a specific persona\n",
    "prompt_role = \"You are an experienced data scientist. Explain overfitting in simple terms.\"\n",
    "\n",
    "response_role = model.generate_content(prompt_role)\n",
    "print(\"\\n Role-based Output:\\n\", response_role.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ra1ERhoqnyaZ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMIdDFLvAH79DqTq90p431Z",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
